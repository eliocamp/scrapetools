% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/map_curl.R
\name{map_curl}
\alias{map_curl}
\alias{attempts}
\title{Fetch and process data from multiple URLs asyncronously}
\usage{
map_curl(urls, .f = identity, ..., .logfile = NULL, .verbose = TRUE,
  .files = NULL, .total_con = 100L, .host_con = 6L, .timeout = Inf,
  .delay = 0, .handle_opts = list(low_speed_limit = 100, low_speed_time
  = 30), .handle_headers = NULL, .handle_form = NULL, .retry = 1)

attempts(x)
}
\arguments{
\item{urls}{a character vector or URLs to scrape.  If names, the return}

\item{.f}{A function or purrr-style lambda to process return values with. Its
first argument, a [curl::curl_fetch_memory()] response.}

\item{...}{further arguments passed to .f}

\item{.logfile}{If not NULL, a file to write messages to. Messages are
appended.}

\item{.verbose}{Whether to write messages to the console}

\item{.files}{A character vector of filenames the same length as `urls`, to
write the content of responses to.}

\item{.total_con}{Total number of connections allowed at the same time}

\item{.host_con}{Connections allowed to a single host at the same time}

\item{.timeout}{Timeout for the whole process}

\item{.delay}{Either a number in seconds or a zero-argument function that
genrates a single number.}

\item{.handle_opts}{a list of options passed [curl::handle_setopt()]. Can be
a list of lists the same length as `urls`.}

\item{.handle_headers}{a list of options passed [curl::handle_setheaders()]
Can be a list of lists the same length as `urls`.}

\item{.handle_form}{a list of options passed [curl::handle_setform()] Can be
a list of lists the same length as `urls`.}

\item{.retry}{Number of times to retry any URL that fails}

\item{x}{an object of class `map_curl`, returned by `map_curl()`}
}
\value{
A list of responses of class `map_curl`.  Failed responses will be
  `NULL` values. Names will be the URLs unless `urls` was a named vector, in
  which case its names will be used. The number of attempts made on each URL
  can be retrieved by calling `attempts()` on the result.
}
\description{
Uses the [*curl* package's async API][curl::multi()] to fetch data from
multiple URLs asyncronously, processing them through a *purrr*-style
functional if needed.  Timeout, retry, delay, and handle options provide
tools to support politely but efficiently fetching data from slow,
unreliable, underpowered sites.
}
